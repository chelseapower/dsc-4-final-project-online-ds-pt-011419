{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/nowplayingrs/sentiment_values.csv\n/kaggle/input/nowplayingrs/user_track_hashtag_timestamp.csv\n/kaggle/input/nowplayingrs/context_content_features.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## OBSERVER & SCRUB: Understand the Datasets and Data Preparation\n\n* Data type conversions (e.g. numeric data mistakenly encoded as objects)\n* Detect and deal with missing values\n* Remove unnecessary columns"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/nowplayingrs/sentiment_values.csv')\n\n#Look at size of the dataset\ndf1.shape","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"(5290, 17)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look at the columns and initial rows of the dataset\ndf1.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                               hashtag   vader_min   vader_max   vader_sum  \\\nrelaxtime         0.8 0.8 2.4      0.8         NaN         NaN         NaN   \nmelovechilicheese 0.8 0.8 0.8      0.8         NaN         NaN         NaN   \ngreatmusic        0.8 0.8 2.4      0.8         1.0         1.0         1.0   \nrockballad        0.7 0.7 0.7      0.7         NaN         NaN         NaN   \namonamarth        0.3 0.3 0.3      0.3         NaN         NaN         NaN   \n\n                               vader_avg    afinn_min   afinn_max   afinn_sum  \\\nrelaxtime         0.8 0.8 2.4        NaN       0.7375      0.7375      0.7375   \nmelovechilicheese 0.8 0.8 0.8        NaN       0.9000      0.9000      0.9000   \ngreatmusic        0.8 0.8 2.4        1.0       0.8875      0.8875      0.8875   \nrockballad        0.7 0.7 0.7        NaN          NaN         NaN         NaN   \namonamarth        0.3 0.3 0.3        NaN          NaN         NaN         NaN   \n\n                                afinn_avg   ol_min   ol_max   ol_sum   ol_avg  \\\nrelaxtime         0.8 0.8 2.4      0.7375      NaN      NaN      NaN      NaN   \nmelovechilicheese 0.8 0.8 0.8      0.9000      1.0      1.0      1.0      1.0   \ngreatmusic        0.8 0.8 2.4      0.8875      1.0      1.0      1.0      1.0   \nrockballad        0.7 0.7 0.7         NaN      NaN      NaN      NaN      NaN   \namonamarth        0.3 0.3 0.3         NaN      0.0      0.0      0.0      0.0   \n\n                                ss_min   ss_max   ss_sum   ss_avg  \nrelaxtime         0.8 0.8 2.4      NaN      NaN      NaN      NaN  \nmelovechilicheese 0.8 0.8 0.8      0.8      0.8      0.8      0.8  \ngreatmusic        0.8 0.8 2.4      0.8      0.8      0.8      0.8  \nrockballad        0.7 0.7 0.7      NaN      NaN      NaN      NaN  \namonamarth        0.3 0.3 0.3      NaN      NaN      NaN      NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>hashtag</th>\n      <th>vader_min</th>\n      <th>vader_max</th>\n      <th>vader_sum</th>\n      <th>vader_avg</th>\n      <th>afinn_min</th>\n      <th>afinn_max</th>\n      <th>afinn_sum</th>\n      <th>afinn_avg</th>\n      <th>ol_min</th>\n      <th>ol_max</th>\n      <th>ol_sum</th>\n      <th>ol_avg</th>\n      <th>ss_min</th>\n      <th>ss_max</th>\n      <th>ss_sum</th>\n      <th>ss_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>relaxtime</th>\n      <th>0.8</th>\n      <th>0.8</th>\n      <th>2.4</th>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7375</td>\n      <td>0.7375</td>\n      <td>0.7375</td>\n      <td>0.7375</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>melovechilicheese</th>\n      <th>0.8</th>\n      <th>0.8</th>\n      <th>0.8</th>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.9000</td>\n      <td>0.9000</td>\n      <td>0.9000</td>\n      <td>0.9000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>greatmusic</th>\n      <th>0.8</th>\n      <th>0.8</th>\n      <th>2.4</th>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.8875</td>\n      <td>0.8875</td>\n      <td>0.8875</td>\n      <td>0.8875</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>rockballad</th>\n      <th>0.7</th>\n      <th>0.7</th>\n      <th>0.7</th>\n      <td>0.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>amonamarth</th>\n      <th>0.3</th>\n      <th>0.3</th>\n      <th>0.3</th>\n      <td>0.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rename hashtag column\ndf1.rename(columns = {'hashtag':'ss_score'}, inplace = True)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##### Reset index\ndf1.reset_index(inplace=True)\n\n#Rename columns\ndf1.rename(columns = {'level_0':'hashtag','level_1':'vader_score','level_2':'afinn_score','level_3':'ol_score'}, inplace = True)\n\n#Show dataset to confirm changes\ndf1.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"             hashtag  vader_score  afinn_score  ol_score  ss_score  \\\n0          relaxtime          0.8          0.8       2.4       0.8   \n1  melovechilicheese          0.8          0.8       0.8       0.8   \n2         greatmusic          0.8          0.8       2.4       0.8   \n3         rockballad          0.7          0.7       0.7       0.7   \n4         amonamarth          0.3          0.3       0.3       0.3   \n\n    vader_min   vader_max   vader_sum  vader_avg    afinn_min  ...  \\\n0         NaN         NaN         NaN        NaN       0.7375  ...   \n1         NaN         NaN         NaN        NaN       0.9000  ...   \n2         1.0         1.0         1.0        1.0       0.8875  ...   \n3         NaN         NaN         NaN        NaN          NaN  ...   \n4         NaN         NaN         NaN        NaN          NaN  ...   \n\n    afinn_sum   afinn_avg   ol_min   ol_max   ol_sum   ol_avg   ss_min  \\\n0      0.7375      0.7375      NaN      NaN      NaN      NaN      NaN   \n1      0.9000      0.9000      1.0      1.0      1.0      1.0      0.8   \n2      0.8875      0.8875      1.0      1.0      1.0      1.0      0.8   \n3         NaN         NaN      NaN      NaN      NaN      NaN      NaN   \n4         NaN         NaN      0.0      0.0      0.0      0.0      NaN   \n\n    ss_max   ss_sum   ss_avg  \n0      NaN      NaN      NaN  \n1      0.8      0.8      0.8  \n2      0.8      0.8      0.8  \n3      NaN      NaN      NaN  \n4      NaN      NaN      NaN  \n\n[5 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hashtag</th>\n      <th>vader_score</th>\n      <th>afinn_score</th>\n      <th>ol_score</th>\n      <th>ss_score</th>\n      <th>vader_min</th>\n      <th>vader_max</th>\n      <th>vader_sum</th>\n      <th>vader_avg</th>\n      <th>afinn_min</th>\n      <th>...</th>\n      <th>afinn_sum</th>\n      <th>afinn_avg</th>\n      <th>ol_min</th>\n      <th>ol_max</th>\n      <th>ol_sum</th>\n      <th>ol_avg</th>\n      <th>ss_min</th>\n      <th>ss_max</th>\n      <th>ss_sum</th>\n      <th>ss_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relaxtime</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.7375</td>\n      <td>...</td>\n      <td>0.7375</td>\n      <td>0.7375</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>melovechilicheese</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.9000</td>\n      <td>...</td>\n      <td>0.9000</td>\n      <td>0.9000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>greatmusic</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.8875</td>\n      <td>...</td>\n      <td>0.8875</td>\n      <td>0.8875</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rockballad</td>\n      <td>0.7</td>\n      <td>0.7</td>\n      <td>0.7</td>\n      <td>0.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>amonamarth</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set columns\ndf1.columns=['hashtag','vader_score','afinn_score','ol_score','ss_score','vader_min','vader_max','vader_sum','vader_avg','afinn_min',\n            'afinn_max','afinn_sum','afinn_avg','ol_min','ol_max','ol_sum','ol_avg','ss_min','ss_max','ss_sum','ss_avg']","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following 12 columns are unecessary and will be removed from the data set:\n\n- **vader_min**: no valuable information, will use vader_score instead\n- **vader_max**: no valuable information, will use vader_score instead\n- **vader_sum**: no valuable information, will use vader_score instead\n- **affin_min**: no valuable information, will use affin_score instead\n- **affin_max**: no valuable information, will use affin_score instead\n- **affin_sum**: no valuable information, will use affin_score instead\n- **ol_min**: no valuable information, will use ol_score instead\n- **ol_max**: no valuable information, will use ol_score instead\n- **ol_sum**: no valuable information, will use ol_score instead\n- **ss_min**: no valuable information, will use ss_score instead\n- **ss_max**: no valuable information, will use ss_score instead\n- **ss_sum**: no valuable information, will use ss_score instead"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tweets = df1.drop(['vader_min','vader_max','vader_sum','afinn_min','afinn_max','afinn_sum','ol_min','ol_max','ol_sum','ss_min','ss_max','ss_sum'], axis=1)\ndf_tweets.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"             hashtag  vader_score  afinn_score  ol_score  ss_score  vader_avg  \\\n0          relaxtime          0.8          0.8       2.4       0.8        NaN   \n1  melovechilicheese          0.8          0.8       0.8       0.8        NaN   \n2         greatmusic          0.8          0.8       2.4       0.8        1.0   \n3         rockballad          0.7          0.7       0.7       0.7        NaN   \n4         amonamarth          0.3          0.3       0.3       0.3        NaN   \n\n   afinn_avg  ol_avg  ss_avg  \n0     0.7375     NaN     NaN  \n1     0.9000     1.0     0.8  \n2     0.8875     1.0     0.8  \n3        NaN     NaN     NaN  \n4        NaN     0.0     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hashtag</th>\n      <th>vader_score</th>\n      <th>afinn_score</th>\n      <th>ol_score</th>\n      <th>ss_score</th>\n      <th>vader_avg</th>\n      <th>afinn_avg</th>\n      <th>ol_avg</th>\n      <th>ss_avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relaxtime</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>0.7375</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>melovechilicheese</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>NaN</td>\n      <td>0.9000</td>\n      <td>1.0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>greatmusic</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>2.4</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>0.8875</td>\n      <td>1.0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rockballad</td>\n      <td>0.7</td>\n      <td>0.7</td>\n      <td>0.7</td>\n      <td>0.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>amonamarth</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tweets.info()","execution_count":8,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5290 entries, 0 to 5289\nData columns (total 9 columns):\nhashtag        5290 non-null object\nvader_score    3867 non-null float64\nafinn_score    3867 non-null float64\nol_score       3867 non-null float64\nss_score       3867 non-null float64\nvader_avg      255 non-null float64\nafinn_avg      2635 non-null float64\nol_avg         2823 non-null float64\nss_avg         2160 non-null float64\ndtypes: float64(8), object(1)\nmemory usage: 372.1+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill in missing vader_score with vader_avg score, if available\ndf_tweets['vader_score'] = df_tweets.apply(\n    lambda row: row['vader_avg'] if np.isnan(row['vader_score']) else row['vader_score'],\n    axis=1\n)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vader_score didn't change\ndf_tweets.info()","execution_count":10,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5290 entries, 0 to 5289\nData columns (total 9 columns):\nhashtag        5290 non-null object\nvader_score    3871 non-null float64\nafinn_score    3867 non-null float64\nol_score       3867 non-null float64\nss_score       3867 non-null float64\nvader_avg      255 non-null float64\nafinn_avg      2635 non-null float64\nol_avg         2823 non-null float64\nss_avg         2160 non-null float64\ndtypes: float64(8), object(1)\nmemory usage: 372.1+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill in missing afinn_score with afinn_avg score, if available\ndf_tweets['afinn_score'] = df_tweets.apply(\n    lambda row: row['afinn_avg'] if np.isnan(row['afinn_score']) else row['afinn_score'],\n    axis=1\n)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#afinn_score increased from 3867 to 4532\ndf_tweets.info()","execution_count":12,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5290 entries, 0 to 5289\nData columns (total 9 columns):\nhashtag        5290 non-null object\nvader_score    3871 non-null float64\nafinn_score    4532 non-null float64\nol_score       3867 non-null float64\nss_score       3867 non-null float64\nvader_avg      255 non-null float64\nafinn_avg      2635 non-null float64\nol_avg         2823 non-null float64\nss_avg         2160 non-null float64\ndtypes: float64(8), object(1)\nmemory usage: 372.1+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill in missing ol_score with ol_avg score, if available\ndf_tweets['ol_score'] = df_tweets.apply(\n    lambda row: row['ol_avg'] if np.isnan(row['ol_score']) else row['ol_score'],\n    axis=1\n)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ol_score increased from 3867 to 4831\ndf_tweets.info()","execution_count":14,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5290 entries, 0 to 5289\nData columns (total 9 columns):\nhashtag        5290 non-null object\nvader_score    3871 non-null float64\nafinn_score    4532 non-null float64\nol_score       4831 non-null float64\nss_score       3867 non-null float64\nvader_avg      255 non-null float64\nafinn_avg      2635 non-null float64\nol_avg         2823 non-null float64\nss_avg         2160 non-null float64\ndtypes: float64(8), object(1)\nmemory usage: 372.1+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill in missing ss_score with ss_avg score, if available\ndf_tweets['ss_score'] = df_tweets.apply(\n    lambda row: row['ss_avg'] if np.isnan(row['ss_score']) else row['ss_score'],\n    axis=1\n)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ss_score increased from 3867 to 4471\ndf_tweets.info()","execution_count":16,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5290 entries, 0 to 5289\nData columns (total 9 columns):\nhashtag        5290 non-null object\nvader_score    3871 non-null float64\nafinn_score    4532 non-null float64\nol_score       4831 non-null float64\nss_score       4471 non-null float64\nvader_avg      255 non-null float64\nafinn_avg      2635 non-null float64\nol_avg         2823 non-null float64\nss_avg         2160 non-null float64\ndtypes: float64(8), object(1)\nmemory usage: 372.1+ KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove all of the unnecessary scores - ol_score has the highest amount of ratings per hashtag\ndf_tweets = df_tweets.drop(['vader_score','afinn_score','ss_score','vader_avg','afinn_avg','ol_avg','ss_avg'], axis=1)\ndf_tweets.head()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"             hashtag  ol_score\n0          relaxtime       2.4\n1  melovechilicheese       0.8\n2         greatmusic       2.4\n3         rockballad       0.7\n4         amonamarth       0.3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hashtag</th>\n      <th>ol_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relaxtime</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>melovechilicheese</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>greatmusic</td>\n      <td>2.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rockballad</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>amonamarth</td>\n      <td>0.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load second dataset\ndf2 = pd.read_csv('../input/nowplayingrs/user_track_hashtag_timestamp.csv')\n\n#Look at size of the dataset\ndf2.shape","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(17560113, 4)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Look at the columns and initial rows of the dataset\ndf2.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"      user_id                          track_id     hashtag  \\\n0    81496937  cd52b3e5b51da29e5893dba82a418a4b  nowplaying   \n1    81496937  cd52b3e5b51da29e5893dba82a418a4b        goth   \n2    81496937  cd52b3e5b51da29e5893dba82a418a4b   deathrock   \n3    81496937  cd52b3e5b51da29e5893dba82a418a4b    postpunk   \n4  2205686924  da3110a77b724072b08f231c9d6f7534  NowPlaying   \n\n            created_at  \n0  2014-01-01 05:54:21  \n1  2014-01-01 05:54:21  \n2  2014-01-01 05:54:21  \n3  2014-01-01 05:54:21  \n4  2014-01-01 05:54:22  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>track_id</th>\n      <th>hashtag</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>81496937</td>\n      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n      <td>nowplaying</td>\n      <td>2014-01-01 05:54:21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>81496937</td>\n      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n      <td>goth</td>\n      <td>2014-01-01 05:54:21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>81496937</td>\n      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n      <td>deathrock</td>\n      <td>2014-01-01 05:54:21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81496937</td>\n      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n      <td>postpunk</td>\n      <td>2014-01-01 05:54:21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2205686924</td>\n      <td>da3110a77b724072b08f231c9d6f7534</td>\n      <td>NowPlaying</td>\n      <td>2014-01-01 05:54:22</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check for null values\ndf2.apply(lambda x: x.isnull().sum())","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"user_id       0\ntrack_id      0\nhashtag       1\ncreated_at    0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop null row\ndf2.dropna(subset=['hashtag'], inplace=True)\ndf2.apply(lambda x: x.isnull().sum())","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"user_id       0\ntrack_id      0\nhashtag       0\ncreated_at    0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the count of the track_id\ncounts = df2['track_id'].value_counts()\n\n# Select the items where the track_id count is less than 10 and remove them\ndf2 = df2[~df2['track_id'].isin(counts[counts < 10].index)]\n\n# Show info\ndf2.info()","execution_count":22,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 16873184 entries, 0 to 17560112\nData columns (total 4 columns):\nuser_id       int64\ntrack_id      object\nhashtag       object\ncreated_at    object\ndtypes: int64(1), object(3)\nmemory usage: 643.7+ MB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Merge CSV files into a single file based on hashtag\ndf_sentiment = pd.merge(df_tweets, df2, on=\"hashtag\", how='inner')\ndf_sentiment.head()","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"             hashtag  ol_score     user_id                          track_id  \\\n0          relaxtime       2.4   104415394  9175ac1532ee7dbe97602866efabac58   \n1          relaxtime       2.4   240771401  c2da30eb3450e8a3e5bfa16e8fa527da   \n2          relaxtime       2.4   637256774  dcbb5aff8f96a79be9f59bc0e7b5c38d   \n3  melovechilicheese       0.8  2438833016  76ed33b994cc15575614b91284b965bb   \n4         greatmusic       2.4   252330820  8f2ac86abb8bd48273c8fc95b632e347   \n\n            created_at  \n0  2014-05-20 07:24:40  \n1  2014-10-12 22:46:57  \n2  2014-11-07 13:01:08  \n3  2014-05-05 23:58:21  \n4  2014-02-13 16:18:51  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hashtag</th>\n      <th>ol_score</th>\n      <th>user_id</th>\n      <th>track_id</th>\n      <th>created_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>relaxtime</td>\n      <td>2.4</td>\n      <td>104415394</td>\n      <td>9175ac1532ee7dbe97602866efabac58</td>\n      <td>2014-05-20 07:24:40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>relaxtime</td>\n      <td>2.4</td>\n      <td>240771401</td>\n      <td>c2da30eb3450e8a3e5bfa16e8fa527da</td>\n      <td>2014-10-12 22:46:57</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>relaxtime</td>\n      <td>2.4</td>\n      <td>637256774</td>\n      <td>dcbb5aff8f96a79be9f59bc0e7b5c38d</td>\n      <td>2014-11-07 13:01:08</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>melovechilicheese</td>\n      <td>0.8</td>\n      <td>2438833016</td>\n      <td>76ed33b994cc15575614b91284b965bb</td>\n      <td>2014-05-05 23:58:21</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>greatmusic</td>\n      <td>2.4</td>\n      <td>252330820</td>\n      <td>8f2ac86abb8bd48273c8fc95b632e347</td>\n      <td>2014-02-13 16:18:51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Confirm null values in new dataframe\ndf_sentiment.apply(lambda x: x.isnull().sum())","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"hashtag           0\nol_score      69714\nuser_id           0\ntrack_id          0\ncreated_at        0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fill all null values for ol_score column with zeros\ndf_sentiment['ol_score'].fillna(0, inplace=True)\ndf_sentiment.info()","execution_count":25,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 5873847 entries, 0 to 5873846\nData columns (total 5 columns):\nhashtag       object\nol_score      float64\nuser_id       int64\ntrack_id      object\ncreated_at    object\ndtypes: float64(1), int64(1), object(3)\nmemory usage: 268.9+ MB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now that the two CSV files are joined, due to the inner join, the new dataframe `df_join` is reduced to **5,873,847** rows (from 17,560,114)."},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_sentiment.to_csv('../input/nowplayingrs/sentiment_cleaned.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load third dataset and limit it to only load 22 columns\ndf3 = pd.read_csv('../input/nowplayingrs/context_content_features.csv', usecols=range(0, 22))\n\n#Look at size of the dataset\ndf3.shape","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"(11614671, 22)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the count of the track_id\ncounts = df3['track_id'].value_counts()\n\n# Select the items where the track_id count is less than 10 and remove them\ndf3 = df3[~df3['track_id'].isin(counts[counts < 10].index)]\n\n# Show info\ndf3.info()","execution_count":28,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 10887911 entries, 0 to 11614670\nData columns (total 22 columns):\ncoordinates         object\ninstrumentalness    float64\nliveness            float64\nspeechiness         float64\ndanceability        float64\nvalence             float64\nloudness            float64\ntempo               float64\nacousticness        float64\nenergy              float64\nmode                float64\nkey                 float64\nartist_id           object\nplace               object\ngeo                 object\ntweet_lang          object\ntrack_id            object\ncreated_at          object\nlang                object\ntime_zone           object\nuser_id             float64\nid                  int64\ndtypes: float64(12), int64(1), object(9)\nmemory usage: 1.9+ GB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop unnecessary/duplicate columns before merging with df_join dataframe\ndf3 = df3.drop(['user_id','coordinates','id','place','geo'], axis=1)\ndf3.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"   instrumentalness  liveness  speechiness  danceability  valence  loudness  \\\n0           0.00479    0.1800       0.0294         0.634    0.342    -8.345   \n1           0.01770    0.0638       0.0624         0.769    0.752    -8.252   \n2           0.00000    0.0860       0.0436         0.675    0.775    -4.432   \n3           0.00000    0.1430       0.0292         0.324    0.333    -5.647   \n5           0.00000    0.1100       0.0375         0.641    0.912    -4.271   \n\n     tempo  acousticness  energy  mode  key                         artist_id  \\\n0  125.044       0.00035   0.697   1.0  6.0  b2980c722a1ace7a30303718ce5491d8   \n1   95.862       0.26700   0.826   1.0  7.0  5cddcd0e314e2f2223ab21937d2c8778   \n2   97.030       0.21700   0.885   0.0  1.0  e41273f43af504714d85465294f1f369   \n3   74.101       0.23900   0.574   1.0  7.0  557ce373bd29743eb00a3723ab19ebe8   \n5   93.010       0.02680   0.787   1.0  0.0  f965ec352eb8c0efc0af46244754942f   \n\n  tweet_lang                          track_id           created_at lang  \\\n0         en  cd52b3e5b51da29e5893dba82a418a4b  2014-01-01 05:54:21   en   \n1         en  da3110a77b724072b08f231c9d6f7534  2014-01-01 05:54:22   en   \n2         en  ba84d88c10fb0e42d4754a27ead10546  2014-01-01 05:54:22   es   \n3         en  33f95122281f76e7134f9cbea3be980f  2014-01-01 05:54:24   en   \n5         en  8bd5206b84c968eda0af8bc86d6ab1d1  2014-01-01 05:54:25   en   \n\n                     time_zone  \n0   Central Time (US & Canada)  \n1                          NaN  \n2  Mountain Time (US & Canada)  \n3   Eastern Time (US & Canada)  \n5   Central Time (US & Canada)  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>speechiness</th>\n      <th>danceability</th>\n      <th>valence</th>\n      <th>loudness</th>\n      <th>tempo</th>\n      <th>acousticness</th>\n      <th>energy</th>\n      <th>mode</th>\n      <th>key</th>\n      <th>artist_id</th>\n      <th>tweet_lang</th>\n      <th>track_id</th>\n      <th>created_at</th>\n      <th>lang</th>\n      <th>time_zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00479</td>\n      <td>0.1800</td>\n      <td>0.0294</td>\n      <td>0.634</td>\n      <td>0.342</td>\n      <td>-8.345</td>\n      <td>125.044</td>\n      <td>0.00035</td>\n      <td>0.697</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>b2980c722a1ace7a30303718ce5491d8</td>\n      <td>en</td>\n      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n      <td>2014-01-01 05:54:21</td>\n      <td>en</td>\n      <td>Central Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.01770</td>\n      <td>0.0638</td>\n      <td>0.0624</td>\n      <td>0.769</td>\n      <td>0.752</td>\n      <td>-8.252</td>\n      <td>95.862</td>\n      <td>0.26700</td>\n      <td>0.826</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>5cddcd0e314e2f2223ab21937d2c8778</td>\n      <td>en</td>\n      <td>da3110a77b724072b08f231c9d6f7534</td>\n      <td>2014-01-01 05:54:22</td>\n      <td>en</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.00000</td>\n      <td>0.0860</td>\n      <td>0.0436</td>\n      <td>0.675</td>\n      <td>0.775</td>\n      <td>-4.432</td>\n      <td>97.030</td>\n      <td>0.21700</td>\n      <td>0.885</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>e41273f43af504714d85465294f1f369</td>\n      <td>en</td>\n      <td>ba84d88c10fb0e42d4754a27ead10546</td>\n      <td>2014-01-01 05:54:22</td>\n      <td>es</td>\n      <td>Mountain Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.00000</td>\n      <td>0.1430</td>\n      <td>0.0292</td>\n      <td>0.324</td>\n      <td>0.333</td>\n      <td>-5.647</td>\n      <td>74.101</td>\n      <td>0.23900</td>\n      <td>0.574</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>557ce373bd29743eb00a3723ab19ebe8</td>\n      <td>en</td>\n      <td>33f95122281f76e7134f9cbea3be980f</td>\n      <td>2014-01-01 05:54:24</td>\n      <td>en</td>\n      <td>Eastern Time (US &amp; Canada)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.00000</td>\n      <td>0.1100</td>\n      <td>0.0375</td>\n      <td>0.641</td>\n      <td>0.912</td>\n      <td>-4.271</td>\n      <td>93.010</td>\n      <td>0.02680</td>\n      <td>0.787</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>f965ec352eb8c0efc0af46244754942f</td>\n      <td>en</td>\n      <td>8bd5206b84c968eda0af8bc86d6ab1d1</td>\n      <td>2014-01-01 05:54:25</td>\n      <td>en</td>\n      <td>Central Time (US &amp; Canada)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert created_at column to datetime\ndf3['created_at'] = pd.to_datetime(df3['created_at'])\ndf3.info()","execution_count":30,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 10887911 entries, 0 to 11614670\nData columns (total 17 columns):\ninstrumentalness    float64\nliveness            float64\nspeechiness         float64\ndanceability        float64\nvalence             float64\nloudness            float64\ntempo               float64\nacousticness        float64\nenergy              float64\nmode                float64\nkey                 float64\nartist_id           object\ntweet_lang          object\ntrack_id            object\ncreated_at          datetime64[ns]\nlang                object\ntime_zone           object\ndtypes: datetime64[ns](1), float64(11), object(5)\nmemory usage: 1.5+ GB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Rename created_at column\ndf3.rename(columns = {'created_at':'timestamp'}, inplace = True)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop all null value rows\ndf3 = df3.dropna()\ndf3.shape","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"(7781780, 17)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Reduced the dataset from 10,887,911 to **7,781,780** by dropping all null value rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"#df3.to_csv('../input/nowplayingrs/features_cleaned.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import dask.dataframe as dd\n\n#Merge df_sentiment and df3 CSV files into new CSV file based on track_id\ndf4 = dd.merge(df_sentiment, df3, on=\"track_id\", how='inner')\ndf4.head()","execution_count":33,"outputs":[{"output_type":"error","ename":"MemoryError","evalue":"Unable to allocate array with shape (4826764770,) and data type int64","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-cd4492e158b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Merge df_sentiment and df3 CSV files into new CSV file based on track_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"track_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dask/dataframe/multi.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, suffixes, indicator, npartitions, shuffle, max_branch)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         )\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     )\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indicator_pre_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    858\u001b[0m             )\n\u001b[1;32m    859\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;34m\"\"\" return the join indexers \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         return _get_join_indexers(\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m         )\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0mjoin_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_join_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjoin_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/join.pyx\u001b[0m in \u001b[0;36mpandas._libs.join.inner_join\u001b[0;34m()\u001b[0m\n","\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (4826764770,) and data type int64"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create new dataframe based on datetime range for training set\ndf_training = df4.loc['2014-01-01':'2014-09-30']\ndf_training.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create new dataframe based on datetime range for test set\ndf_test = df4.loc['2014-11-01':'2014-12-23']\ndf_test.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}