{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"student.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"eqDoad7P0KUD","colab_type":"text"},"source":["## Module 4 Final Project Submission\n","\n","Please fill out:\n","* Student name: **Chelsea Power**\n","* Student pace: **part time**\n","* Scheduled project review date/time: **8/30/19 at 5 pm ET**\n","* Instructor name: **Brandon Lewis**\n","* Blog post URL: \n"]},{"cell_type":"markdown","metadata":{"id":"DkCtlp2-8IAM","colab_type":"text"},"source":["## Purpose\n","\n","This project will focus on predicting customer mood for the purpose of song recommendation and maintaining listener engagement. A neural network will be used to predict the song mood (emotion variation of a user based on the track they are playing). Then based on the output of the neural network, a conext-aware recommendation system will recommend the next song.\n","\n","## Data Dictionary\n","\n","**# nowplaying-RS Dataset (3 files)**\n","\n","This dataset features context- and content features of listening events. It contains 11.6 million music listening events of 139K users and 346K tracks collected from Twitter. The dataset comes with a rich set of item content features and user context features, as well as timestamps of the listening events. Moreover, some of the user context features imply the cultural origin of the users, and some others - like hashtags - give clues to the emotional state of a user underlying a listening event.\n","\n","- **user_track_hashtag_timestamp.csv** contains basic information about each listening event. Provided in each listening event: id, the user_id, track_id, hashtag, created_at\n","- **context_content_features.csv** contains all context and content features. Provided in each listening event: the id of the event, user_id, track_id, artist_id, content features regarding the track mentioned in the event (instrumentalness, liveness, speechiness, danceability, valence, loudness, tempo, acousticness, energy, mode, key) and context features regarding the listening event (coordinates (as geoJSON), place (as geoJSON), geo (as geoJSON), tweet_language, created_at, user_lang, time_zone, entities contained in the tweet).\n","- **sentiment_values.csv** contains sentiment information for hashtags. It contains the hashtag itself and the sentiment values gathered via four different sentiment dictionaries: AFINN, Opinion Lexicon, Sentistrength Lexicon and vader. For each of these dictionaries we list the minimum, maximum, sum and average of all sentiments of the tokens of the hashtag (if available, else we list empty values). However, as most hashtags only consist of a single token, these values are equal in most cases. Please note that the lexica are rather diverse and therefore, are able to resolve very different terms against a score. Hence, the resulting csv is rather sparse. The file contains the following comma-separated values: <hashtag, vader_min, vader_max, vader_sum,vader_avg,  afinn_min, afinn_max, afinn_sum, afinn_avg, ol_min, ol_max, ol_sum, ol_avg, ss_min, ss_max, ss_sum, ss_avg >, where we abbreviate all scores gathered over the Opinion Lexicon with the prefix 'ol'. Similarly, 'ss' stands for SentiStrength. "]},{"cell_type":"markdown","metadata":{"id":"PZE8buIr_96g","colab_type":"text"},"source":["### OBSERVE: Understand and Load the Datasets"]},{"cell_type":"code","metadata":{"id":"uh2NtS5tS65h","colab_type":"code","colab":{}},"source":["# Import required libraries\n","import pandas as pd\n","import numpy as np\n","\n","df1 = pd.read_csv('user_track_hashtag_timestamp.csv')\n","\n","#Look at size of the dataset\n","df1.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5wNI2-VALG0","colab_type":"code","colab":{}},"source":["#Look at the columns and first 10 rows of the dataset\n","df1.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ts9KG0hWkJL","colab_type":"code","colab":{}},"source":["#Load second dataset\n","df2 = pd.read_csv('context_content_features.csv')\n","\n","#Look at size of the dataset\n","df2.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aNNbwZuEWsfh","colab_type":"code","colab":{}},"source":["#Look at the columns and first 10 rows of the dataset\n","df2.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzei-MQPWst8","colab_type":"code","colab":{}},"source":["#Load third dataset\n","df3 = pd.read_csv('sentiment_values.csv.csv')\n","\n","#Look at size of the dataset\n","df3.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K7sneJrHWs6N","colab_type":"code","colab":{}},"source":["#Look at the columns and first 10 rows of the dataset\n","df3.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cVuJCbuAXHZz","colab_type":"code","colab":{}},"source":["#Determine how to join datasets - rename columns / drop unnecessary columns per csv file\n","#Merge csv files into new dataset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b2b1aPzUASa-","colab_type":"text"},"source":["### SCRUB: Data Preparation\n","- Data type conversions (e.g. numeric data mistakenly encoded as objects)\n","- Detect and deal with missing values\n","- Remove unnecessary columns"]},{"cell_type":"code","metadata":{"id":"vf5ewucNAY-L","colab_type":"code","colab":{}},"source":["# Look at column types"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OtrJgKGtCHVI","colab_type":"text"},"source":["## Check for null/missing values"]},{"cell_type":"code","metadata":{"id":"3vcYoKQaCLj2","colab_type":"code","colab":{}},"source":["# Run an apply method utilizing a lambda expression that checks to see if there was any missing values through each column. \n","# Printing the column name and total missing values for that column, iteratively.\n","df_music.apply(lambda x: x.isnull().sum())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9s71PmNjAZ1u","colab_type":"text"},"source":["## Explore the data\n","- Look at the distribution for the data\n","- Look for multicolinarity\n","- Remove unnecessary features"]},{"cell_type":"code","metadata":{"id":"c8xWj-IgCaur","colab_type":"code","colab":{}},"source":["#Look at value counts of the predictor variable\n","df_music.XXX.value_counts()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGiuRx3HChqn","colab_type":"code","colab":{}},"source":["# Visualize data\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","sns.countplot(x='XXX', data=df, palette='hls')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-qyDJdPnCnWe","colab_type":"text"},"source":["**Observation:**"]},{"cell_type":"code","metadata":{"id":"_jCFeh1XCqfk","colab_type":"code","colab":{}},"source":["# Create continuous dataset and look at distributions for data\n","df_music ="],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LUwPkRWDCz8r","colab_type":"text"},"source":["**Summary:**"]},{"cell_type":"code","metadata":{"id":"8vOM3ZLOC3qK","colab_type":"code","colab":{}},"source":["#Create coorelation heatmap - check for multicolinarity\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","\n","correlation = df_music.corr()\n","plt.figure(figsize=(14, 12))\n","heatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fQzVGgLkC8Fr","colab_type":"text"},"source":["**Summary:**"]},{"cell_type":"markdown","metadata":{"id":"LuhZrgEtDIvd","colab_type":"text"},"source":["## Model 1: Logistic Regression\n","- Normalize the data prior to fitting the model\n","- Train-Test Split\n","- Fit the model\n","- Predict\n","- Evaluate"]},{"cell_type":"code","metadata":{"id":"c0jonMA1DHhu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OL_lLzT1DTj_","colab_type":"text"},"source":["## Confusion Matrix"]},{"cell_type":"code","metadata":{"id":"wj6ZEn00DRg8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hBjIRwYJDXb_","colab_type":"text"},"source":["## ROC Graph\n","Plot the Receiver Operating Characteristic Curve for both the train and test sets using the false positive rate and true positive rate."]},{"cell_type":"code","metadata":{"id":"jgDacyHqDZX4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o0pznT_PDsu3","colab_type":"text"},"source":["## Decision Tree"]},{"cell_type":"code","metadata":{"id":"slc3Jc_CDu5S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Zj4W4_ODZx9","colab_type":"text"},"source":["## Model 2: Create a Random Forest Classifier"]},{"cell_type":"code","metadata":{"id":"5gLoBzCPDeQM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RV-Hdk96Dfzx","colab_type":"text"},"source":["## XG Boost\n","Build a model that can accurately classify if a track will be skipped based on the features in the dataset."]},{"cell_type":"markdown","metadata":{"id":"YVuLkHnt_Zlg","colab_type":"text"},"source":["### Citation\n","\n","@inproceedings{smc18,\n","title = {#nowplaying-RS: A New Benchmark Dataset for Building Context-Aware Music Recommender Systems},\n","author = {Asmita Poddar and Eva Zangerle and Yi-Hsuan Yang},\n","url = {http://mac.citi.sinica.edu.tw/~yang/pub/poddar18smc.pdf},\n","year = {2018},\n","date = {2018-07-04},\n","booktitle = {Proceedings of the 15th Sound & Music Computing Conference},\n","address = {Limassol, Cyprus},\n","note = {code at https://github.com/asmitapoddar/nowplaying-RS-Music-Reco-FM},\n","tppubtype = {inproceedings}\n","}"]}]}